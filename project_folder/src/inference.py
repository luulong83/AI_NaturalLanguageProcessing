import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import pandas as pd
import os
from utils import load_config, load_model

# M√¥ h√¨nh PhoBERT
class PhoBERTClassifier(nn.Module):
    def __init__(self, phobert_model):
        super().__init__()
        self.phobert = phobert_model
        self.dropout = nn.Dropout(0.1)
        # Lo·∫°i b·ªè l·ªõp classifier t√πy ch·ªânh, s·ª≠ d·ª•ng classifier c·ªßa phobert_model

    def forward(self, input_ids, attention_mask):
        outputs = self.phobert(input_ids, attention_mask=attention_mask)
        return outputs.logits  # Tr·∫£ v·ªÅ logits tr·ª±c ti·∫øp

# D·ª± ƒëo√°n
def predict(model, tokenizer, text, device, max_len=128):
    model.eval()
    inputs = tokenizer.encode_plus(
        text, max_length=max_len, padding="max_length", truncation=True, return_tensors="pt"
    )
    input_ids = inputs["input_ids"].to(device)
    attention_mask = inputs["attention_mask"].to(device)
    
    with torch.no_grad():
        outputs = model(input_ids, attention_mask)
        pred = torch.argmax(outputs, dim=1).cpu().item()
    # C·∫≠p nh·∫≠t √°nh x·∫° cho POS, NEG, NEU
    label_map = {0: "POS", 1: "NEG", 2: "NEU"}
    return label_map.get(pred, "unknown")

if __name__ == "__main__":
    # Load c·∫•u h√¨nh
    config = load_config()
    project_root = config["project_root"]
    model_path = os.path.join(project_root, "models", "phobert_best.pt")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print("üì• ƒêang t·∫£i m√¥ h√¨nh...")
    tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base")
    # S·ª≠ d·ª•ng num_labels=3 ƒë·ªÉ kh·ªõp v·ªõi hu·∫•n luy·ªán
    model = PhoBERTClassifier(AutoModelForSequenceClassification.from_pretrained("vinai/phobert-base", num_labels=3))
    model.load_state_dict(load_model(model_path))
    model = model.to(device)

    # V√≠ d·ª• d·ª± ƒëo√°n
    test_text = "C√¢u n√†y c√≥ t·ª± nhi√™n kh√¥ng?"
    result = predict(model, tokenizer, test_text, device)
    print(f"üìù VƒÉn b·∫£n: {test_text}")
    print(f"üîç D·ª± ƒëo√°n: {result}")

    # D·ª± ƒëo√°n t·ª´ file (tu·ª≥ ch·ªçn)
    input_path = os.path.join(project_root, "data", "raw", "test_5k.csv")
    if os.path.exists(input_path):
        data = pd.read_csv(input_path, usecols=["comment"])
        predictions = [predict(model, tokenizer, text, device) for text in data["comment"]]
        data["prediction"] = predictions
        output_path = os.path.join(project_root, "data", "processed", "predictions.csv")
        data.to_csv(output_path, index=False)
        print(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ d·ª± ƒëo√°n t·∫°i: {output_path}")