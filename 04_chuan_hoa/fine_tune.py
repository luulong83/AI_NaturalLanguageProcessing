from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, pipeline
import pandas as pd
from datasets import Dataset

# --------------------
# 1. Load dá»¯ liá»‡u
# --------------------
train_df = pd.read_csv("data/train.tsv", sep="\t")
val_df = pd.read_csv("data/val.tsv", sep="\t")

# --------------------
# 2. Load tokenizer vÃ  model
# --------------------
try:
    tokenizer = T5Tokenizer.from_pretrained("VietAI/vit5-base")
    model = T5ForConditionalGeneration.from_pretrained("VietAI/vit5-base")
except Exception as e:
    print(f"âŒ Lá»—i táº£i mÃ´ hÃ¬nh hoáº·c tokenizer: {e}")
    exit()

# --------------------
# 3. HÃ m tiá»n xá»­ lÃ½
# --------------------
def preprocess(examples):
    inputs = ["chuan_hoa: " + x for x in examples["input"]]
    model_inputs = tokenizer(inputs, max_length=64, padding="max_length", truncation=True)
    labels = tokenizer(examples["output"], max_length=64, padding="max_length", truncation=True)
    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

try:
    train_dataset = Dataset.from_pandas(train_df).map(preprocess, batched=True)
    val_dataset = Dataset.from_pandas(val_df).map(preprocess, batched=True)
    print("âœ… Máº«u dá»¯ liá»‡u sau tiá»n xá»­ lÃ½:", train_dataset[0])
except Exception as e:
    print(f"âŒ Lá»—i trong tiá»n xá»­ lÃ½: {e}")
    exit()

# --------------------
# 4. Cáº¥u hÃ¬nh huáº¥n luyá»‡n
# --------------------
training_args = TrainingArguments(
    output_dir="./vit5_chuanhoa_model",
    overwrite_output_dir=True,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=20,  # TÄƒng Ä‘á»ƒ há»c tá»‘t hÆ¡n
    learning_rate=5e-5,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    save_total_limit=3,
    logging_dir="./logs",
    logging_strategy="steps",
    logging_steps=10,
    load_best_model_at_end=True,
    metric_for_best_model="loss",
    report_to="none",
    fp16=False,
    gradient_accumulation_steps=1,
)

# --------------------
# 5. Táº¡o Trainer vÃ  huáº¥n luyá»‡n
# --------------------
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    tokenizer=tokenizer,
)

try:
    trainer.train()
except Exception as e:
    print(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n: {e}")
    exit()

# --------------------
# 6. LÆ°u mÃ´ hÃ¬nh vÃ  tokenizer
# --------------------
try:
    trainer.save_model("./vit5_chuanhoa_model")
    tokenizer.save_pretrained("./vit5_chuanhoa_model")
    print("âœ… MÃ´ hÃ¬nh vÃ  tokenizer Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o ./vit5_chuanhoa_model")
except Exception as e:
    print(f"âŒ Lá»—i khi lÆ°u mÃ´ hÃ¬nh: {e}")

# --------------------
# 7. Kiá»ƒm tra tokenizer
# --------------------
print("ğŸ” Kiá»ƒm tra tokenizer:")
test_input = "chuan_hoa: mik k hieu j het"
encoded = tokenizer(test_input, return_tensors="pt")
decoded = tokenizer.decode(encoded.input_ids[0], skip_special_tokens=True)
print(f"Input: {test_input}")
print(f"Encoded input_ids: {encoded.input_ids}")
print(f"Decoded back: {decoded}")

# --------------------
# 8. Kiá»ƒm tra mÃ´ hÃ¬nh
# --------------------
print("\nğŸ” Kiá»ƒm tra mÃ´ hÃ¬nh:")
model.eval()

# Kiá»ƒm tra vá»›i pipeline
try:
    pipe = pipeline("text2text-generation", model=model, tokenizer=tokenizer)
    test_inputs = [
        "chuan_hoa: mik k hieu j het",
        "chuan_hoa: t ko bik j lun",
        "chuan_hoa: cx muon di chs nhug k co time"
    ]
    print("\nğŸ“Œ Kiá»ƒm tra vá»›i pipeline:")
    for test_input in test_inputs:
        result = pipe(
            test_input,
            max_new_tokens=128,
            num_beams=5,
            early_stopping=True,
            do_sample=False,
            no_repeat_ngram_size=2
        )
        print(f"ğŸ§ª Raw pipeline output: {result}")
        print(f"ğŸ›  Input: {test_input}")
        print(f"âœ… Output: {result[0]['generated_text'] if result else 'No output generated'}")
        print()
except Exception as e:
    print(f"âŒ Lá»—i khi cháº¡y pipeline: {e}")

# Kiá»ƒm tra sinh vÄƒn báº£n thá»§ cÃ´ng
print("\nğŸ“Œ Kiá»ƒm tra sinh vÄƒn báº£n thá»§ cÃ´ng:")
for test_input in test_inputs:
    try:
        input_ids = tokenizer(test_input, return_tensors="pt").input_ids
        output_ids = model.generate(
            input_ids,
            max_length=128,
            num_beams=10,
            early_stopping=True,
            do_sample=False,
            no_repeat_ngram_size=3
        )
        output = tokenizer.decode(output_ids[0], skip_special_tokens=True)
        print(f"ğŸ›  Input: {test_input}")
        print(f"âœ… Manual output: {output}")
        print()
    except Exception as e:
        print(f"âŒ Lá»—i khi sinh vÄƒn báº£n thá»§ cÃ´ng: {e}")

# --------------------
# 9. Log quÃ¡ trÃ¬nh huáº¥n luyá»‡n
# --------------------
print("ğŸ“‰ Train Loss:", trainer.state.log_history)